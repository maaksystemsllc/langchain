# LlamaEdge

>[LlamaEdge](https://github.com/second-state/LlamaEdge) package allows you to chat with LLMs of [GGUF](https://github.com/ggerganov/llama.cpp/blob/master/gguf-py/README.md) format both locally and via chat service.
>
>- `LlamaEdgeChatService` provides developers an OpenAI API compatible service to chat with LLMs via HTTP requests.


## Installation and setup

See the [installation instructions](https://www.secondstate.io/articles/run-llm-sh/)


## Chat models

See a [usage example](/docs/integrations/chat/llama_edge).

```python
from langchain_community.chat_models.llama_edge import LlamaEdgeChatService
```
