# Llama API

>[Llama API](https://docs.llama-api.com/quickstart) allows your application to interact with many models seamlessly, 
> abstracting the handling of `aiohttp` sessions and headers, allowing for a simplified interaction.
> 
> See the [available models](https://docs.llama-api.com/quickstart#available-models)
> currently available through `LlamaAPI`.


## Installation and setup

- Install the `llamaapi` integration package.

  ```bash
  pip install llamaapi
  ```

See the [instructions here](https://docs.llama-api.com/quickstart#python).


## Chat models

See a [usage example](/docs/integrations/chat/llama_api).

```python
from langchain_experimental.llms import ChatLlamaAPI
```
