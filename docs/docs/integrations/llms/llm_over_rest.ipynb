{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169eda47-d480-4311-9556-74e900e892a7",
   "metadata": {},
   "source": [
    "# LLM Over REST\n",
    "\n",
    "This notebook explains how to use the LLM Over REST integration with LangChain. There is no additional dependencies that you would need to install. It uses `httpx` under the hood, if it is available, otherwise falling back to `requests`.\n",
    "\n",
    "\n",
    "## Configuration Parameters\n",
    "\n",
    "Most of basic HTTP configurations are available as parameters during initialization of the LLM object. There is a provision to pass a Callable to create the JSON body for the REST API from the prompt, stop-words and other model parameters. By default, it adds the prompt and stop-words as keys `prompt` and `stop` respectively at the root of the JSON, and appends the entire model parameters object to the JSON. An example of how to provide a custom implementation is provided below.\n",
    "\n",
    "## Advanced SSL settings\n",
    "\n",
    "SSL settings are controlled via `ssl_verify` and `client_certs` parameters. \n",
    "\n",
    "### Disabling Server Certificate Check\n",
    "\n",
    "You can set the parameter `ssl_verify` to `False` in order to disable validating the server certificate. In this case, even basic checks like Certificate expiry, Certificate and Server name mismatches are also ignored. **This mode is not recommended for production use as it makes your application vulnerable to Man-in-the-Middle attacks**\n",
    "\n",
    "### Adding Custom CAs\n",
    "`ssl_verify` can be set to the path for the CA certificate file in case you want to use custom Certificate Authorities to validate certificates. If the path is a folder it should be rehashed using `openssl rehash`\n",
    "\n",
    "### Using Client Certificates for mTLS\n",
    "To authenticate the client with the server via mTLS, you can set the parameter `client_certs` parameter. It can either be a string to the path for the client certificate or a two-Tuple containing the path to the client certificate and the *unencrypted* private key file for the client.\n",
    "\n",
    "## Generating the JSON body\n",
    "Users can provide a Callable to generate the JSON body for the request. The method takes three parameters - a prompt string, an optional list of stop words and a dictionary containing all other model parameters. By default, the JSON Body is structured like:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"prompt\": prompt,\n",
    "    \"stop\": stop,\n",
    "}.update(model_kwargs)\n",
    "```\n",
    "\n",
    "The callable should return a `Dict[str, Any]` by combining all the parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7f0f0a-34cd-454c-a2c2-bfa3f580ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.llm_over_rest import LLMOverREST\n",
    "from typing import Optional, List, Dict, Any\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77981c1-de30-4585-b9ca-4e6e8124d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json(prompt: str, \n",
    "                stop: Optional[List[str]] = None, \n",
    "                model_kwargs: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    try:\n",
    "        model_params = model_kwargs.get(\"parameters\") or {}\n",
    "        model_kwargs[\"prompt\"] = prompt\n",
    "        if stop and len(stop) > 0:\n",
    "            model_params[\"stop\"] = stop\n",
    "    except BaseException as e:\n",
    "        raise ValueError(f\"Error in creating json: {e}\")\n",
    "\n",
    "    return model_kwargs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1218fc2d-ef6a-4ad4-85ac-8da5f82cb1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The world did not end in 2012 as the Mayans predicted.ðŸ¤«\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    \"X-Auth-Key\": secrets.get_password(\"auth-key\"),\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "  \"model\": \"highly-secret-llm\",\n",
    "  \"parameters\": {\n",
    "    \"max_new_tokens\": 2023,\n",
    "    \"return_full_text\": True,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "  }\n",
    "}\n",
    "\n",
    "llm = LLMOverREST(api_endpoint=\"https://llmgateway.mycompany.com/v1/generate\",\n",
    "                  method=\"POST\",\n",
    "                  headers=headers,\n",
    "                  ssl_verify=\"/etc/ssl/certs/ca-certificates\",\n",
    "                  model_kwargs=json_body,\n",
    "                  json_body_creator=create_json_wmt_endpoint\n",
    "                 )\n",
    "response = llm(\"Tell me something highly secret\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b520228-4fed-474a-8b8f-058af2913eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
